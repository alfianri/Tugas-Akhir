\chapter{Perhitungan Manual \textit{Activation Function}}
\label{Perhitungan Manual Activation Function}

\subsection*{1. \textit{Sigmoid}}
Fungsi aktivasi \textit{sigmoid} mendefinisikan output sebagai:
\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]

Contoh: Misalkan \( x = 1.5 \).

Langkah-langkah:
\begin{enumerate}
    \item Hitung \( e^{-x} \):
    \[
    e^{-1.5} \approx 0.2231
    \]

    \item Tambahkan 1 ke hasil tersebut:
    \[
    1 + 0.2231 = 1.2231
    \]

    \item Hitung kebalikan (1 per hasil tersebut):
    \[
    \frac{1}{1.2231} \approx 0.8176
    \]
\end{enumerate}

Jadi, nilai aktivasi \textit{sigmoid} untuk \( x = 1.5 \) adalah sekitar \( 0.8176 \).

\subsection*{2. \textit{Softmax}}
Fungsi aktivasi \textit{softmax} menghitung probabilitas dari beberapa kelas. Untuk vektor input \(\mathbf{x} = [x_1, x_2, x_3, \ldots, x_n]\), fungsi \textit{softmax} mendefinisikan \textit{output} sebagai:
\[
\sigma(x_i) = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
\]

Contoh: Misalkan \(\mathbf{x} = [2.0, 1.0, 0.1]\).

Langkah-langkah:
\begin{enumerate}
    \item Hitung \( e^{x_i} \) untuk setiap elemen:
    \[
    e^{2.0} \approx 7.389
    \]
    \[
    e^{1.0} \approx 2.718
    \]
    \[
    e^{0.1} \approx 1.105
    \]

    \item Hitung jumlah semua hasil eksponensial:
    \[
    7.389 + 2.718 + 1.105 = 11.212
    \]

    \item Hitung setiap probabilitas dengan membagi hasil eksponensial masing-masing elemen dengan jumlah total:
    \[
    \sigma(x_1) = \frac{7.389}{11.212} \approx 0.659
    \]
    \[
    \sigma(x_2) = \frac{2.718}{11.212} \approx 0.242
    \]
    \[
    \sigma(x_3) = \frac{1.105}{11.212} \approx 0.099
    \]
\end{enumerate}

Jadi, hasil \textit{softmax} untuk \(\mathbf{x} = [2.0, 1.0, 0.1]\) adalah sekitar \([0.659, 0.242, 0.099]\).

\subsection*{3. ReLU (\textit{Rectified Linear Unit})}
Fungsi aktivasi ReLU mendefinisikan output sebagai:
\[
\text{ReLU}(x) = \max(0, x)
\]

Contoh: Misalkan \( x = -2.0, 1.0, 0.0, 3.5 \).

Langkah-langkah:
\begin{enumerate}
    \item Untuk \( x = -2.0 \):
    \[
    \text{ReLU}(-2.0) = \max(0, -2.0) = 0
    \]

    \item Untuk \( x = 1.0 \):
    \[
    \text{ReLU}(1.0) = \max(0, 1.0) = 1.0
    \]

    \item Untuk \( x = 0.0 \):
    \[
    \text{ReLU}(0.0) = \max(0, 0.0) = 0
    \]

    \item Untuk \( x = 3.5 \):
    \[
    \text{ReLU}(3.5) = \max(0, 3.5) = 3.5
    \]
\end{enumerate}

Jadi, hasil ReLU untuk \( x = [-2.0, 1.0, 0.0, 3.5] \) adalah \([0, 1.0, 0, 3.5]\).



\chapter{Perhitungan Manual \textit{Optimizer}}
\label{Perhitungan Manual Optimizer}


\subsection*{1. \textit{Stochastic Gradient Descent} (SGD)}

\subsection*{Persamaan}
\begin{align}
    W & = \omega - \eta \cdot \nabla Q_i(\omega) \\
    Q(\omega) & = \ln\left(\sum_i Q_i(\omega)\right) \\
    \nabla Q(\omega) & = \ln\left(\sum_i \nabla Q_i(\omega)\right)
\end{align}



\subsection*{Keterangan:}
\begin{itemize}
    \item \( W \): Parameter model yang akan diperbarui.
    \item \( \omega \): Nilai parameter \( W \) saat ini.
    \item \( \eta \): Learning rate.
    \item \( Q_i(\omega) \): Nilai fungsi \( Q_i \) untuk contoh data ke-i.
    \item \( Q(\omega) = \ln\left(\sum_i Q_i(\omega)\right) \).
    \item \( \nabla Q(\omega) = \ln\left(\sum_i \nabla Q_i(\omega)\right) \).
\end{itemize}


\subsection*{Contoh Perhitungan}
Misalkan kita memiliki dua contoh data (\( i = 1, 2 \)), dengan:
\begin{itemize}
    \item Nilai parameter saat ini: \( \omega = 1.0 \)
    \item Learning rate: \( \eta = 0.1 \)
    \item Fungsi \( Q_1(\omega) = \omega^2 \) dan \( Q_2(\omega) = 2\omega \)
\end{itemize}

Langkah-langkah perhitungan manual:

1. Hitung nilai \( Q_i(\omega) \) untuk \( \omega = 1.0 \):
   \begin{align*}
       Q_1(1.0) & = (1.0)^2 = 1.0 \\
       Q_2(1.0) & = 2 \cdot 1.0 = 2.0
   \end{align*}

2. Hitung nilai \( Q(\omega) \):
   \[
   Q(\omega) = \ln\left(Q_1(\omega) + Q_2(\omega)\right) = \ln(1.0 + 2.0) = \ln(3.0)
   \]

3. Hitung gradien \( \nabla Q_i(\omega) \):
   \begin{align*}
       \nabla Q_1(\omega) & = \frac{d}{d\omega}(\omega^2) = 2\omega \\
       \nabla Q_2(\omega) & = \frac{d}{d\omega}(2\omega) = 2
   \end{align*}
   Jadi, untuk \( \omega = 1.0 \):
   \begin{align*}
       \nabla Q_1(1.0) & = 2 \cdot 1.0 = 2 \\
       \nabla Q_2(1.0) & = 2
   \end{align*}

4. Hitung gradien \( \nabla Q(\omega) \):
   \[
   \nabla Q(\omega) = \ln\left(\nabla Q_1(\omega) + \nabla Q_2(\omega)\right) = \ln(2 + 2) = \ln(4)
   \]

5. Pembaruan parameter \( W \):
   \begin{align*}
       W & = \omega - \eta \cdot \nabla Q(\omega) \\
       & = 1.0 - 0.1 \cdot \ln(4)
   \end{align*}
   Menghitung nilai \( \ln(4) \approx 1.386 \):
   \[
   W = 1.0 - 0.1 \cdot 1.386 = 1.0 - 0.1386 = 0.8614
   \]

\subsection*{Kesimpulan}
Parameter model \( W \) setelah satu iterasi pembaruan menggunakan SGD adalah \( W \approx 0.8614 \).

\vspace{3 cm}


\section*{1. \textit{Adaptive Moment Estimation } (Adam)}

\subsection*{Persamaan:}
    \begin{equation}
    \begin{aligned}
        x_t &= \delta_1 \cdot x_{t-1} - (1 - \delta_1) \cdot g_t \\
        y_t &= \delta_2 \cdot y_{t-1} - (1 - \delta_2) \cdot g_t^2 \\
        \Delta \omega_t &= -\eta \frac{x_t}{\sqrt{y_t + \epsilon}} \cdot g_t \\
        \omega_{t+1} &= \omega_t + \Delta \omega_t
    \end{aligned}
    \label{Adam}
    \end{equation}

 \textbf{Keterangan:}

    \begin{align*}
    x_t &: \text{Estimasi pertama dari rata-rata gradien pada iterasi ke-t}\\
    y_t &: \text{Estimasi kedua dari rata-rata gradien kedua pada iterasi ke-t}\\
    \omega_t &: \text{\textit{Learning rate} yang disesuaikan pada iterasi ke-t}\\
    g_t &: \text{Gradien dari parameter pada iterasi ke-t}\\
    \delta_1, \delta_2 &: \text{Hyperparameter untuk estimasi pertama dan kedua terhadap gradien baru}\\
    \eta &: \text{\textit{Learning rate}}\\
\end{align*}



\subsection*{Diberikan:}
\begin{itemize}
    \item $\delta_1$: Hyperparameter untuk estimasi pertama dari rata-rata gradien (biasanya sekitar 0.9)
    \item $\delta_2$: Hyperparameter untuk estimasi kedua dari rata-rata gradien kedua (biasanya sekitar 0.999)
    \item $\eta$: Learning rate (biasanya nilai kecil seperti 0.001)
    \item $\epsilon$: Nilai kecil untuk menghindari pembagian dengan nol (biasanya $10^{-8}$)
    \item $g_t$: Gradien dari parameter pada iterasi ke-t
\end{itemize}



\subsection*{Contoh Perhitungan:}
Misalkan nilai awal sebagai berikut:
\begin{itemize}
    \item $x_0 = 0$
    \item $y_0 = 0$
    \item $\omega_0 = 0.5$
    \item $\delta_1 = 0.9$
    \item $\delta_2 = 0.999$
    \item $\eta = 0.001$
    \item $\epsilon = 10^{-8}$
    \item $g_1 = 0.1$
\end{itemize}

\subsubsection*{Iterasi Pertama ($t=1$):}
\begin{align}
    x_1 &= \delta_1 \cdot x_0 + (1 - \delta_1) \cdot g_1 \nonumber \\
    &= 0.9 \cdot 0 + (1 - 0.9) \cdot 0.1 \nonumber \\
    &= 0.01
\end{align}

\begin{align}
    y_1 &= \delta_2 \cdot y_0 + (1 - \delta_2) \cdot g_1^2 \nonumber \\
    &= 0.999 \cdot 0 + (1 - 0.999) \cdot (0.1)^2 \nonumber \\
    &= 0.00001
\end{align}

\begin{align}
    \Delta \omega_1 &= -\eta \frac{x_1}{\sqrt{y_1} + \epsilon} \cdot g_1 \nonumber \\
    &= -0.001 \frac{0.01}{\sqrt{0.00001} + 10^{-8}} \cdot 0.1 \nonumber \\
    &= -0.001 \frac{0.01}{0.003162 + 10^{-8}} \cdot 0.1 \nonumber \\
    &= -0.001 \frac{0.01}{0.003162} \cdot 0.1 \nonumber \\
    &= -0.001 \cdot 3.162 \cdot 0.1 \nonumber \\
    &= -0.0003162
\end{align}

\begin{align}
    \omega_1 &= \omega_0 + \Delta \omega_1 \nonumber \\
    &= 0.5 - 0.0003162 \nonumber \\
    &= 0.4996838
\end{align}

\subsubsection*{Iterasi Kedua ($t=2$):}
Misalkan gradien $g_2 = 0.2$
\begin{align}
    x_2 &= \delta_1 \cdot x_1 + (1 - \delta_1) \cdot g_2 \nonumber \\
    &= 0.9 \cdot 0.01 + (1 - 0.9) \cdot 0.2 \nonumber \\
    &= 0.009 + 0.02 \nonumber \\
    &= 0.029
\end{align}

\begin{align}
    y_2 &= \delta_2 \cdot y_1 + (1 - \delta_2) \cdot g_2^2 \nonumber \\
    &= 0.999 \cdot 0.00001 + (1 - 0.999) \cdot (0.2)^2 \nonumber \\
    &= 0.00000999 + 0.00004 \nonumber \\
    &= 0.00004999
\end{align}

\begin{align}
    \Delta \omega_2 &= -\eta \frac{x_2}{\sqrt{y_2} + \epsilon} \cdot g_2 \nonumber \\
    &= -0.001 \frac{0.029}{\sqrt{0.00004999} + 10^{-8}} \cdot 0.2 \nonumber \\
    &= -0.001 \frac{0.029}{0.00707 + 10^{-8}} \cdot 0.2 \nonumber \\
    &= -0.001 \frac{0.029}{0.00707} \cdot 0.2 \nonumber \\
    &= -0.001 \cdot 4.1 \cdot 0.2 \nonumber \\
    &= -0.00082
\end{align}

\begin{align}
    \omega_2 &= \omega_1 + \Delta \omega_2 \nonumber \\
    &= 0.4996838 - 0.00082 \nonumber \\
    &= 0.4988638
\end{align}

\subsection*{Ringkasan}
\begin{itemize}
    \item Iterasi 1: $\omega_1 = 0.4996838$
    \item Iterasi 2: $\omega_2 = 0.4988638$
\end{itemize}
